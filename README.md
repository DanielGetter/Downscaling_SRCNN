# Description 

This is a code repository for "Statistical treatment of convolutional neural network super-resolution of inland surface wind for subgrid-scale variability quantification" by Getter, Bessac, Rudi and Feng (submitted Feb 2023). The submitted draft can be found [here](https://arxiv.org/pdf/2211.16708.pdf).

**ABSTRACT**              
Machine learning (ML) models have been recently employed to perform either physics-free data driven or hybrid dynamical downscaling of climate data. However, most of these ML implementations operate over relatively small downscaling factors of about 4–6x due the challenge of recovering fine-scale information from coarse one, which limits the application of a vast amount of global climate model outputs that are available but often in ∼50-100 km grid spacing to the scales of interest, e.g., cloud resolving or urban scales at several kilometers (km), by downscaling. This study systematically examines the capability of convolutional neural networks (CNN) to downscale the surface wind speed data over land surface from three different coarse resolutions (25 km, 48km, and 100 km side-length grid cells) to 3 km. For each downscaling factor, namely 8x, 16x, and 32x, we consider three sets of CNN configurations that generate super-resolved predictions of fine- scale wind speed as a function of different input features: coarse wind fields only; coarse wind and fine-scale topography; and coarse wind, topography, and diurnal cycle in the form of a timestamp. In addition to the fine-scale wind speeds, probability density function parameters are generated, through which sample wind speeds can be generated to account for the intrinsic stochasticity of wind speed. For generalizalibility assessment, CNN models are tested on regions with different topography and climate that are unseen during training. The evaluation of super-resolved pre- dictions focuses on subgrid-scale variability and the recovery of extremes. All the CNN models outperform the bicubic interpolation on out-of-sample data in downscaling. Models with coarse wind and fine topography as input features exhibit the best performance compared to other model configurations, operating across the same downscaling factor. Our timestamp encoding results in lower out-of-sample generalizability compared to other  nput configurations, which we discuss in the study.
